{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0066abe2ce4d7e924fa29b1bc44c871156ee10f281f3a85f9639772cbbc29f11b",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "game_data = pd.read_csv('data/game_info.csv', index_col=0)\n",
    "user_data_train = pd.read_csv('data/user_data_train_no_comments.csv', index_col=0)\n",
    "user_data_validation = pd.read_csv('data/user_data_validation_no_comments.csv', index_col=0)\n",
    "user_data_train_validation = pd.concat([user_data_train, user_data_validation])\n",
    "user_data_test = pd.read_csv('data/user_data_test_no_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of game data to consider in content-based filtering for computing similarities\n",
    "content_categories = ['Title', 'Publisher', 'Year', 'Genre', 'Platform']\n",
    "\n",
    "def get_bag(category):\n",
    "    '''\n",
    "    Return a bag of words for tf-idf vectorization given the category name\n",
    "    '''\n",
    "    processing_func = None\n",
    "    if category == 'Title':\n",
    "        processing_func = lambda s: s.split()\n",
    "    elif category == 'Publisher':\n",
    "        processing_func = lambda s: s.split(',')\n",
    "    elif category == 'Genre':\n",
    "        processing_func = lambda s: s.split(';')\n",
    "    else:\n",
    "        processing_func = lambda s: [str(s)]\n",
    "\n",
    "    return game_data[category].apply(processing_func)\n",
    "\n",
    "def get_similarity_matrix(categories, vectorizer):\n",
    "    '''\n",
    "    Return the cosine similarity matrix using the given categories\n",
    "    '''\n",
    "    assert categories # assert it is not an empty list\n",
    "\n",
    "    # retrieve a bag of words per game to vectorize\n",
    "    bag_of_texts = get_bag(categories[0])\n",
    "    for category in categories[1:]:\n",
    "        bag_of_texts += get_bag(category)\n",
    "\n",
    "    # create a tf-idf vectorizor that filters out non-alphanumeric characters and ignores case\n",
    "    tf = TfidfVectorizer(analyzer=lambda i: map(lambda s: ''.join(filter(str.isalnum, s.lower())), i))\n",
    "\n",
    "    # compute the tf-idf matrix\n",
    "    tfidf_matrix = tf.fit_transform(bag_of_texts)\n",
    "\n",
    "    # compute and return the cosine similarity matrix\n",
    "    return cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# compute the cosine similarity matrix\n",
    "similarity_matrix = get_similarity_matrix(content_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_prediction(test_dataset, similarity_matrix, rating):\n",
    "    '''\n",
    "    Make a prediction about the userscore of a particular rating based on the user's rating of other games in the test_dataset\n",
    "    '''\n",
    "    # get all ratings from the user\n",
    "    user_ratings = test_dataset[test_dataset.Username == rating.Username]\n",
    "    user_ratings = user_ratings.set_index('Game_ID')\n",
    "    user_ratings = user_ratings.drop(rating.Game_ID, errors='ignore') # Remove the game rating we are predicting\n",
    "    game_sims = similarity_matrix[user_ratings.index, rating.Game_ID]\n",
    "    sim_sum = sum(game_sims)\n",
    "    if sim_sum == 0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return sum(user_ratings.Userscore * game_sims) / sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_predictions(test_dataset, similarity_matrix):\n",
    "    '''\n",
    "    Make predictions for every rating from a given test_dataset using a given similarity matrix.\n",
    "    If a prediction can not be made, the game's mean userscore from game_mean_userscores is predicted instead.\n",
    "    If a prediciton can not be made and the game is not in the game_mean_userscores dataset, predict the fallback_score.\n",
    "    '''\n",
    "    return test_dataset.apply(lambda row: content_based_prediction(test_dataset, similarity_matrix, row), axis=1)\n",
    "\n",
    "def game_mean_userscores_predictions(test_dataset, training_dataset):\n",
    "    '''\n",
    "    For each row in the test_dataset, give the game's average userscore if available.\n",
    "    '''\n",
    "    game_mean_userscores = training_dataset.groupby('Game_ID').mean()\n",
    "    return game_mean_userscores.reindex(test_dataset.Game_ID).set_index(test_dataset.index).Userscore\n",
    "\n",
    "def training_mean_predictions(test_dataset, training_dataset):\n",
    "    '''\n",
    "    For each row in the test_dataset, give the game's average userscore if available.\n",
    "    '''\n",
    "    return pd.Series(np.ones(len(test_dataset.Userscore)) * training_dataset.Userscore.mean(), index=test_dataset.index)\n",
    "\n",
    "def compute_rmse(test_dataset, predictions):\n",
    "    '''\n",
    "    Compute RMSE on the test_dataset given the predictions.\n",
    "    If a prediction is NaN, then the prediction is ignored and does not contribute to the RMSE.\n",
    "    The index of the predictions must be a subset or equal of the test_dataset index.\n",
    "    '''\n",
    "    num_dropped = len(test_dataset) - len(predictions[predictions.notna()])\n",
    "    if num_dropped:\n",
    "        print('NaN predictions detected.', num_dropped, ' ( out of', len(test_dataset), ') data points have been excluded from the RMSE.')\n",
    "    return mean_squared_error(predictions[predictions.notna()], test_dataset.Userscore[predictions.notna()], squared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = user_data_train_validation\n",
    "test_dataset = user_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make predictions using the content-based filtering\n",
    "'''\n",
    "preds = content_based_predictions(test_dataset, similarity_matrix)\n",
    "preds_rmse = compute_rmse(test_dataset, preds)\n",
    "preds_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Baseline 1 - Predict only the mean user score from training data\n",
    "'''\n",
    "tm_preds = training_mean_predictions(test_dataset, training_dataset)\n",
    "tm_preds_rmse = compute_rmse(test_dataset, tm_preds)\n",
    "tm_preds_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Baseline 2 - Predict the mean userscore of a game from the training data\n",
    "'''\n",
    "gmu_preds = game_mean_userscores_predictions(test_dataset, training_dataset)\n",
    "gmu_preds_rmse = compute_rmse(test_dataset, gmu_preds)\n",
    "gmu_preds_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finished with with the datasets\n",
    "'''\n",
    "del user_data_train\n",
    "del user_data_validation\n",
    "del user_data_train_validation\n",
    "del user_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Permutation test\n",
    "'''\n",
    "# Set a seed for reproducible results\n",
    "seed = 8175615\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set number of permutations\n",
    "num_permutations = 100\n",
    "RMSEs = np.zeros(num_permutations)\n",
    "\n",
    "# Create new data splits\n",
    "\n",
    "user_data = pd.read_csv('data/user_data_no_comments.csv', index_col=0)\n",
    "# Remove anonymous users\n",
    "user_data = user_data[user_data[\"Username\"] != \"[Anonymous]\"]\n",
    "user_data = user_data[user_data[\"Username\"] != \"AnonymousMC\"]\n",
    "# Remove users with less than 3 reviews\n",
    "user_data = user_data.groupby('Username')\n",
    "user_data = user_data.filter(lambda x: len(x) > 2)\n",
    "\n",
    "for i in range(num_permutations):\n",
    "\n",
    "    print('iteration', i)\n",
    "\n",
    "    # Shuffle the user score column of the user data\n",
    "    permuted_user_data = user_data.copy()\n",
    "    permuted_userscores = user_data.Userscore.sample(frac=1)\n",
    "    permuted_userscores.index = user_data.Userscore.index\n",
    "    permuted_user_data.Userscore = permuted_userscores\n",
    "    user_groups = permuted_user_data.groupby('Username')\n",
    "\n",
    "    # Take 20% of the data to test on\n",
    "    _, test_groups = train_test_split(\n",
    "        list(user_groups), \n",
    "        train_size=.8\n",
    "    )\n",
    "    randomized_test_set = pd.concat([x[1] for x in test_groups])\n",
    "\n",
    "    # Make predictions\n",
    "    preds = content_based_predictions(randomized_test_set, similarity_matrix)\n",
    "    rmse = compute_rmse(randomized_test_set, preds)\n",
    "    RMSEs[i] = rmse\n",
    "    print('RMSE', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save RMSEs to a CSV\n",
    "'''\n",
    "RMSE_series = pd.Series(RMSEs)\n",
    "RMSE_series.to_csv('permutation_test_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Show histogram of permutation test results alongside the true test result\n",
    "'''\n",
    "plt.hist(RMSEs)\n",
    "plt.axvline(preds_rmse, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.xlabel('RMSE')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Permutation Test Scores')\n",
    "plt.savefig('perm_test_hist.png', dpi=600)"
   ]
  }
 ]
}