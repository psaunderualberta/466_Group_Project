{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "066abe2ce4d7e924fa29b1bc44c871156ee10f281f3a85f9639772cbbc29f11b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import swifter # parallelization for pandas (e.g. parallel .apply)\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "game_data = pd.read_csv('data/game_info.csv', index_col=0)\n",
    "user_data_train = pd.read_csv('data/user_data_train_no_comments.csv', index_col=0)\n",
    "user_data_validation = pd.read_csv('data/user_data_validation_no_comments.csv', index_col=0)\n",
    "user_data_train_validation = pd.concat([user_data_train, user_data_validation])\n",
    "user_data_test = pd.read_csv('data/user_data_test_no_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories of game data to consider in content-based filtering for computing similarities\n",
    "content_categories = ['Title', 'Publisher', 'Year', 'Genre', 'Platform']\n",
    "\n",
    "def get_bag(category):\n",
    "    '''\n",
    "    Return a bag of words for tf-idf vectorization given the category name\n",
    "    '''\n",
    "    processing_func = None\n",
    "    if category == 'Title':\n",
    "        processing_func = lambda s: s.split() # split title on whitespace\n",
    "    elif category == 'Genre':\n",
    "        processing_func = lambda s: s.split(';') # split genre on semicolons\n",
    "    else:\n",
    "        processing_func = lambda s: [str(s)]\n",
    "\n",
    "    return game_data[category].apply(processing_func)\n",
    "\n",
    "def get_similarity_matrix(categories):\n",
    "    '''\n",
    "    Return the cosine similarity matrix using the given categories\n",
    "    '''\n",
    "    assert categories # assert it is not an empty list\n",
    "\n",
    "    # retrieve a bag of words per game to vectorize\n",
    "    bag_of_texts = get_bag(categories[0])\n",
    "    for category in categories[1:]:\n",
    "        bag_of_texts += get_bag(category)\n",
    "\n",
    "    # create a tf-idf vectorizor that filters out non-alphanumeric characters and ignores case\n",
    "    tf = TfidfVectorizer(analyzer=lambda i: map(lambda s: ''.join(filter(str.isalnum, s.lower())), i))\n",
    "\n",
    "    # compute the tf-idf matrix\n",
    "    tfidf_matrix = tf.fit_transform(bag_of_texts)\n",
    "\n",
    "    # compute and return the cosine similarity matrix\n",
    "    return cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# compute the cosine similarity matrix\n",
    "similarity_matrix = get_similarity_matrix(content_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_prediction(test_dataset, similarity_matrix, rating):\n",
    "    '''\n",
    "    Make a prediction about the userscore of a particular rating based on the user's rating of other games in the test_dataset\n",
    "    '''\n",
    "    # get all ratings from the user\n",
    "    user_ratings = test_dataset[test_dataset.Username == rating.Username]\n",
    "    user_ratings = user_ratings.set_index('Game_ID')\n",
    "    user_ratings = user_ratings.drop(rating.Game_ID, errors='ignore') # Remove the game rating we are predicting\n",
    "    game_sims = similarity_matrix[user_ratings.index, rating.Game_ID]\n",
    "    sim_sum = sum(game_sims)\n",
    "    if sim_sum == 0:\n",
    "        return np.NaN\n",
    "    else:\n",
    "        return sum(user_ratings.Userscore * game_sims) / sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_predictions(test_dataset, similarity_matrix):\n",
    "    '''\n",
    "    Make predictions for every rating from a given test_dataset using a given similarity matrix.\n",
    "    If a prediction can not be made, the game's mean userscore from game_mean_userscores is predicted instead.\n",
    "    If a prediciton can not be made and the game is not in the game_mean_userscores dataset, predict the fallback_score.\n",
    "    '''\n",
    "    return test_dataset.swifter.apply(lambda row: content_based_prediction(test_dataset, similarity_matrix, row), axis=1)\n",
    "\n",
    "def game_mean_userscores_predictions(test_dataset, training_dataset):\n",
    "    '''\n",
    "    For each row in the test_dataset, give the game's average userscore if available.\n",
    "    '''\n",
    "    game_mean_userscores = training_dataset.groupby('Game_ID').mean()\n",
    "    return game_mean_userscores.reindex(test_dataset.Game_ID).set_index(test_dataset.index).Userscore\n",
    "\n",
    "def training_mean_predictions(test_dataset, training_dataset):\n",
    "    '''\n",
    "    For each row in the test_dataset, give the game's average userscore if available.\n",
    "    '''\n",
    "    return pd.Series(np.ones(len(test_dataset.Userscore)) * training_dataset.Userscore.mean(), index=test_dataset.index)\n",
    "\n",
    "def compute_rmse(test_dataset, predictions):\n",
    "    '''\n",
    "    Compute RMSE on the test_dataset given the predictions.\n",
    "    If a prediction is NaN, then the prediction is ignored and does not contribute to the RMSE.\n",
    "    The index of the predictions must be a subset or equal of the test_dataset index.\n",
    "    '''\n",
    "    num_dropped = len(test_dataset) - len(predictions[predictions.notna()])\n",
    "    if num_dropped:\n",
    "        print('NaN predictions detected.', num_dropped, ' ( out of', len(test_dataset), ') data points have been excluded from the RMSE.')\n",
    "    return mean_squared_error(predictions[predictions.notna()], test_dataset.Userscore[predictions.notna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = user_data_train\n",
    "test_dataset = user_data_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value='Pandas Apply'), FloatProgress(value=0.0, max=14918.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84c4d6d066734043b0862e459fb86b43"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nNaN predictions detected. 265  ( out of 14918 ) data points have been excluded from the RMSE.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7.034192919056081"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "preds = content_based_predictions(test_dataset, similarity_matrix)\n",
    "compute_rmse(test_dataset, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7.281932273516624"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "tm_preds = training_mean_predictions(test_dataset, training_dataset)\n",
    "compute_rmse(test_dataset, tm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NaN predictions detected. 31  ( out of 14918 ) data points have been excluded from the RMSE.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.883357220654495"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "gmu_preds = game_mean_userscores_predictions(test_dataset, training_dataset)\n",
    "compute_rmse(test_dataset, gmu_preds)"
   ]
  }
 ]
}